{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA6RJ2VybPrbNdQ6yU4+7o"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNmznJUSXuVU",
        "outputId": "b1a3c671-f34f-4bb1-af71-ca540f308566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n",
        "!pip install torch-scatter torch-sparse torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Example:\n",
        "edge_index = torch.tensor([[1, 2, 3], [0, 0, 0]], dtype = torch.long)\n",
        "x = torch.tensor([[1], [1], [1]], dtype = torch.float)\n",
        "\n",
        "data = Data(edge_index = edge_index, x = x)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btVeCw4mX8Vw",
        "outputId": "3a3a3e0c-580b-4e27-c455-6a2a89b5f45e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[3, 1], edge_index=[2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GCN node classifier implementation"
      ],
      "metadata": {
        "id": "33WSjrFudtY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = torch.tensor([[1], [1], [1]], dtype=torch.float)\n",
        "print(x.shape)\n",
        "i = x.shape[0]\n",
        "print(x.size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRMzURHwuGb0",
        "outputId": "7c816707-be2a-4db6-b95c-eec31c2adc13"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "import math\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch.nn.functional as fct\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "import time\n",
        "from torch import tensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "path = osp.join(os.getcwd(), 'data', 'Cora')\n",
        "dataset = Planetoid(path, 'Cora')\n",
        "\n",
        "''' GCN layer '''\n",
        "def tensor_initialization(tensor):\n",
        "  # Using Glorot method for setting the weights of the tensor to values chosen from\n",
        "  # a uniform distribution within a specific range\n",
        "  if tensor == None:\n",
        "    return\n",
        "  std = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
        "  tensor.data.uniform_(-std, std)\n",
        "\n",
        "def zeros(tensor):\n",
        "  tensor.data.fill_(0)\n",
        "\n",
        "def self_loops(edge_index, num_nodes=None):\n",
        "  loop_idx = torch.arange(0, num_nodes, dtype=torch.long, device=edge_index.device)\n",
        "  loop_idx = loop_idx.unsqueeze(0).repeat(2, 1)\n",
        "  edge_index = torch.cat([edge_index, loop_idx], dim=1)\n",
        "  return edge_index\n",
        "\n",
        "def degree(index, num_nodes, dtype=None):\n",
        "  out = torch.zeros((num_nodes), dtype=dtype, device=index.device)\n",
        "  return out.scatter_add_(0, index, out.new_ones((index.size(0))))\n",
        "\n",
        "class GCN(MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(GCN, self).__init__(aggr='add')\n",
        "    self.linear = torch.nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    tensor_initialization(self.linear.weight)\n",
        "    zeros(self.linear.bias)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x has shape [N, in_channels]\n",
        "    # edge_index has shape [2, E]\n",
        "    self.edge_index = self_loops(edge_index, x.size(0))\n",
        "    x = self.linear(x)\n",
        "    return self.propagate(edge_index, x = x)\n",
        "\n",
        "  def message(self, x_j, edge_index, size):\n",
        "    row, col = edge_index\n",
        "    D = degree(row, size[0], dtype = x_j.dtype)\n",
        "    D_inv_sqrt = D.pow(-0.5)\n",
        "    D_inv_sqrt[D_inv_sqrt == float('inf')] = 0\n",
        "    norm = D_inv_sqrt[row] * D_inv_sqrt[col]\n",
        "\n",
        "    return norm.view(-1, 1) * x_j\n",
        "\n",
        "  def update(self, aggr_out):\n",
        "    return aggr_out\n",
        "\n",
        "\n",
        "''' Model for vertex classification '''\n",
        "def train(model, optimizer, data):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data)\n",
        "  loss = fct.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "def evaluate(model, data):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(data)\n",
        "\n",
        "  outs = dict()\n",
        "  for key in ['train', 'val', 'test']:\n",
        "    mask = data['{}_mask'.format(key)]\n",
        "    loss = fct.nll_loss(logits[mask], data.y[mask]).item()\n",
        "    pred = logits[mask].max(1)[1]\n",
        "    acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "    outs['{}_loss'.format(key)] = loss\n",
        "    outs['{}_acc'.format(key)] = acc\n",
        "\n",
        "  return outs\n",
        "\n",
        "def run(dataset, model, iterations, epochs, lr, weight_decay, early_stop):\n",
        "  val_losses, accs, durations = [], [], []\n",
        "  for _ in range(iterations):\n",
        "    data = dataset[0]\n",
        "    data = data.to(device)\n",
        "    model.to(device).reset_parameters()\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    time_start = time.perf_counter()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    test_accuracy = 0\n",
        "    val_loss_history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      train(model, optimizer, data)\n",
        "      eval_info = evaluate(model, data)\n",
        "      eval_info['epoch'] = epoch\n",
        "\n",
        "      if eval_info['val_loss'] < best_val_loss:\n",
        "          best_val_loss = eval_info['val_loss']\n",
        "          test_acc = eval_info['test_acc']\n",
        "\n",
        "      val_loss_history.append(eval_info['val_loss'])\n",
        "      if early_stop > 0 and epoch > epochs // 2:\n",
        "        tmp = tensor(val_loss_history[-(early_stop + 1):-1])\n",
        "        if eval_info['val_loss'] > tmp.mean().item():\n",
        "          break\n",
        "\n",
        "    time_end = time.perf_counter()\n",
        "    val_losses.append(best_val_loss)\n",
        "    accs.append(test_acc)\n",
        "    durations.append(time_end - time_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "\n",
        "    print('Test Accuracy: {:.3f} ± {:.3f}, Value Loss: {:.4f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))\n",
        "\n",
        "\n",
        "iterations = 10\n",
        "epochs = 200\n",
        "lr = 0.01\n",
        "weight_decay = 0.0005\n",
        "early_stop = 10\n",
        "hidden = 16\n",
        "dropout = 0.5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GCNNet(torch.nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(GCNNet, self).__init__()\n",
        "\n",
        "    self.conv_1 = GCN(dataset.num_features, hidden)\n",
        "    self.conv_2 = GCN(hidden, dataset.num_classes)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self.conv_1.reset_parameters()\n",
        "    self.conv_2.reset_parameters()\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    x = fct.relu(self.conv_1(x, edge_index))\n",
        "    x = fct.dropout(x, p=dropout, training=self.training)\n",
        "    x = self.conv_2(x, edge_index)\n",
        "    return fct.log_softmax(x, dim=1)\n",
        "\n",
        "run(dataset, GCNNet(dataset), iterations, epochs, lr, weight_decay, early_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD9Qf6oIhAGo",
        "outputId": "a78918ac-35ca-447c-c1d4-94e64582e978"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.779 ± 0.786, Value Loss: nan, Duration: 2.822\n",
            "Test Accuracy: 0.775 ± 0.784, Value Loss: 0.0028, Duration: 2.793\n",
            "Test Accuracy: 0.784 ± 0.784, Value Loss: 0.0020, Duration: 3.019\n",
            "Test Accuracy: 0.773 ± 0.782, Value Loss: 0.0039, Duration: 2.905\n",
            "Test Accuracy: 0.763 ± 0.782, Value Loss: 0.0033, Duration: 2.833\n",
            "Test Accuracy: 0.757 ± 0.784, Value Loss: 0.0047, Duration: 2.770\n",
            "Test Accuracy: 0.752 ± 0.783, Value Loss: 0.0043, Duration: 2.786\n",
            "Test Accuracy: 0.744 ± 0.786, Value Loss: 0.0071, Duration: 2.852\n",
            "Test Accuracy: 0.743 ± 0.786, Value Loss: 0.0068, Duration: 2.835\n",
            "Test Accuracy: 0.742 ± 0.787, Value Loss: 0.0067, Duration: 2.817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Classification\n",
        "\n",
        "Using GINs since they are expressive and powerful in what concerns the Weisfeiler-Lehman graph isomorphism test.  "
      ],
      "metadata": {
        "id": "V2J4FDnQgAmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Isomorphism Network"
      ],
      "metadata": {
        "id": "L-6GffD3zv8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models for graph classification\n",
        ""
      ],
      "metadata": {
        "id": "_ZkEPS4U9cvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric.transforms as T\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import tensor\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch_geometric.data import DataLoader, DenseDataLoader as DenseLoader\n",
        "\n",
        "\n",
        "class NormalizedDegree(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, data):\n",
        "        D = degree(data.edge_index[0], dtype=torch.float)\n",
        "        D = (D - self.mean) / self.std\n",
        "        data.x = D.view(-1, 1)\n",
        "        return data\n",
        "\n",
        "\n",
        "def access_dataset(name, cleaned=False):\n",
        "    path = osp.join(os.getcwd(), 'data', name)\n",
        "    dataset = TUDataset(path, name, cleaned=cleaned)\n",
        "    dataset.data.edge_attr = None\n",
        "\n",
        "    if dataset.data.x is None:\n",
        "        max_degree = 0\n",
        "        degs = []\n",
        "        for data in dataset:\n",
        "            degs += [degree(data.edge_index[0], dtype=torch.long)]\n",
        "            max_degree = max(max_degree, degs[-1].max().item())\n",
        "\n",
        "        if max_degree < 1000:\n",
        "            dataset.transform = T.OneHotDegree(max_degree)\n",
        "        else:\n",
        "            deg = torch.cat(degs, dim=0).to(torch.float)\n",
        "            mean, std = deg.mean().item(), deg.std().item()\n",
        "            dataset.transform = NormalizedDegree(mean, std)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def print_dataset(dataset):\n",
        "    num_nodes = num_edges = 0\n",
        "    for data in dataset:\n",
        "        num_nodes += data.num_nodes\n",
        "        num_edges += data.num_edges\n",
        "\n",
        "    print('Name', dataset)\n",
        "    print('Graphs', len(dataset))\n",
        "    print('Nodes', num_nodes / len(dataset))\n",
        "    print('Edges', (num_edges // 2) / len(dataset))\n",
        "    print('Features', dataset.num_features)\n",
        "    print('Classes', dataset.num_classes)\n",
        "    print()\n",
        "\n",
        "\n",
        "for name in ['IMDB-BINARY']:\n",
        "    print_dataset(access_dataset(name))\n",
        "\n",
        "def cross_validation_with_val_set(dataset, model, folds, epochs, batch_size,\n",
        "                                  lr, lr_decay_factor, lr_decay_step_size,\n",
        "                                  weight_decay, logger=None):\n",
        "\n",
        "    val_losses, accuracies, durations = [], [], []\n",
        "    for fold, (train_idx, test_idx,\n",
        "               val_idx) in enumerate(zip(*k_fold(dataset, folds))):\n",
        "\n",
        "        train_dataset = dataset[train_idx]\n",
        "        test_dataset = dataset[test_idx]\n",
        "        val_dataset = dataset[val_idx]\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
        "\n",
        "        model.to(device).reset_parameters()\n",
        "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_start = time.perf_counter()\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_loss = train(model, optimizer, train_loader)\n",
        "            val_losses.append(eval_loss(model, val_loader))\n",
        "            accuracies.append(eval_acc(model, test_loader))\n",
        "            eval_info = {\n",
        "                'fold': fold,\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_losses[-1],\n",
        "                'test_acc': accuracies[-1],\n",
        "            }\n",
        "\n",
        "            if logger is not None:\n",
        "                logger(eval_info)\n",
        "\n",
        "            if epoch % lr_decay_step_size == 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_decay_factor * param_group['lr']\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accuracies), tensor(durations)\n",
        "    loss, acc = loss.view(folds, epochs), acc.view(folds, epochs)\n",
        "    loss, argmin = loss.min(dim=1)\n",
        "    acc = acc[torch.arange(folds, dtype=torch.long), argmin]\n",
        "\n",
        "    loss_mean = loss.mean().item()\n",
        "    acc_mean = acc.mean().item()\n",
        "    acc_std = acc.std().item()\n",
        "    duration_mean = duration.mean().item()\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss_mean, acc_mean, acc_std, duration_mean))\n",
        "\n",
        "    return loss_mean, acc_mean, acc_std\n",
        "\n",
        "\n",
        "def k_fold(dataset, folds):\n",
        "    skf = StratifiedKFold(folds, shuffle=True, random_state=12345)\n",
        "\n",
        "    test_indices, train_indices = [], []\n",
        "    for _, idx in skf.split(torch.zeros(len(dataset)), dataset.data.y):\n",
        "        test_indices.append(torch.from_numpy(idx))\n",
        "\n",
        "    val_indices = [test_indices[i - 1] for i in range(folds)]\n",
        "\n",
        "    for i in range(folds):\n",
        "        train_mask = torch.ones(len(dataset), dtype=torch.bool)\n",
        "        train_mask[test_indices[i]] = 0\n",
        "        train_mask[val_indices[i]] = 0\n",
        "        train_indices.append(train_mask.nonzero().view(-1))\n",
        "\n",
        "    return train_indices, test_indices, val_indices\n",
        "\n",
        "\n",
        "def num_graphs(data):\n",
        "    if data.batch is not None:\n",
        "        return data.num_graphs\n",
        "    else:\n",
        "        return data.x.size(0)\n",
        "\n",
        "\n",
        "def train(model, optimizer, loader):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += loss.item() * num_graphs(data)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def eval_acc(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(data).max(1)[1]\n",
        "        correct += pred.eq(data.y.view(-1)).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def eval_loss(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    loss = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(data)\n",
        "        loss += F.nll_loss(out, data.y.view(-1), reduction='sum').item()\n",
        "    return loss / len(loader.dataset)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN\n",
        "from torch_geometric.nn import global_mean_pool, MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "def reset(nn):\n",
        "    def _reset(item):\n",
        "        if hasattr(item, 'reset_parameters'):\n",
        "            item.reset_parameters()\n",
        "\n",
        "    if nn is not None:\n",
        "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
        "            for item in nn.children():\n",
        "                _reset(item)\n",
        "        else:\n",
        "            _reset(nn)\n",
        "\n",
        "\n",
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, nn, eps=0, train_eps=False, **kwargs):\n",
        "        super(GINConv, self).__init__(aggr='add', **kwargs)\n",
        "        self.nn = nn\n",
        "        self.initial_eps = eps\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.Tensor([eps]))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        reset(self.nn)\n",
        "        self.eps.data.fill_(self.initial_eps)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = remove_self_loops(edge_index)\n",
        "        out = self.nn((1 + self.eps) * x + self.propagate(edge_index, x=x))\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return x_j\n",
        "\n",
        "class GIN0(torch.nn.Module):\n",
        "    def __init__(self, dataset, num_layers, hidden):\n",
        "        super(GIN0, self).__init__()\n",
        "        self.conv_1 = GINConv(Sequential(\n",
        "            Linear(dataset.num_features, hidden),\n",
        "            ReLU(),\n",
        "            Linear(hidden, hidden),\n",
        "            ReLU(),\n",
        "            BN(hidden),\n",
        "        ),\n",
        "                              train_eps=False)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.convs.append(\n",
        "                GINConv(Sequential(\n",
        "                    Linear(hidden, hidden),\n",
        "                    ReLU(),\n",
        "                    Linear(hidden, hidden),\n",
        "                    ReLU(),\n",
        "                    BN(hidden),\n",
        "                ),\n",
        "                        train_eps=False))\n",
        "        self.lin1 = Linear(hidden, hidden)\n",
        "        self.lin2 = Linear(hidden, dataset.num_classes)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, current_batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "        x = global_mean_pool(x, current_batch)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, dataset, num_layers, hidden):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(Sequential(\n",
        "            Linear(dataset.num_features, hidden),\n",
        "            ReLU(),\n",
        "            Linear(hidden, hidden),\n",
        "            ReLU(),\n",
        "            BN(hidden),\n",
        "        ),\n",
        "                             train_eps=True)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.convs.append(\n",
        "                GINConv(Sequential(\n",
        "                    Linear(hidden, hidden),\n",
        "                    ReLU(),\n",
        "                    Linear(hidden, hidden),\n",
        "                    ReLU(),\n",
        "                    BN(hidden),\n",
        "                ),\n",
        "                        train_eps=True))\n",
        "        self.lin1 = Linear(hidden, hidden)\n",
        "        self.lin2 = Linear(hidden, dataset.num_classes)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 12\n",
        "lr = 0.01\n",
        "lr_decay_factor = 0.5\n",
        "lr_decay_step_size = 50\n",
        "\n",
        "layers = [5]\n",
        "hiddens = [64]\n",
        "datasets = ['IMDB-BINARY']\n",
        "nets = [\n",
        "    GIN0,\n",
        "    GIN,\n",
        "]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def logger(info):\n",
        "    fold, epoch = info['fold'] + 1, info['epoch']\n",
        "    val_loss, test_acc = info['val_loss'], info['test_acc']\n",
        "    print('{:02d}/{:03d}: Val Loss: {:.4f}, Test Accuracy: {:.3f}'.format(\n",
        "        fold, epoch, val_loss, test_acc))\n",
        "\n",
        "\n",
        "results = []\n",
        "for dataset_name, Net in product(datasets, nets):\n",
        "    best_result = (float('inf'), 0, 0)  # (loss, acc, std)\n",
        "    print('-----\\n{} - {}'.format(dataset_name, Net.__name__))\n",
        "    for num_layers, hidden in product(layers, hiddens):\n",
        "        dataset = access_dataset(dataset_name)\n",
        "        model = Net(dataset, num_layers, hidden)\n",
        "        loss, acc, std = cross_validation_with_val_set(\n",
        "            dataset,\n",
        "            model,\n",
        "            folds=10,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            lr_decay_factor=lr_decay_factor,\n",
        "            lr_decay_step_size=lr_decay_step_size,\n",
        "            weight_decay=0,\n",
        "            logger=None,\n",
        "        )\n",
        "        if loss < best_result[0]:\n",
        "            best_result = (loss, acc, std)\n",
        "\n",
        "    desc = '{:.5f} +- {:.5f}'.format(best_result[1], best_result[2])\n",
        "    print('The best ans = {}'.format(desc))\n",
        "    results += ['Name = {}, Model = {}, Result = {}'.format(dataset_name, model, desc)]\n",
        "print('-----\\n{}'.format('\\n'.join(results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdrJChv-Aih8",
        "outputId": "8a812368-2b4f-4cf8-da33-3f4c66f8629e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name IMDB-BINARY(1000)\n",
            "Graphs 1000\n",
            "Nodes 19.773\n",
            "Edges 96.531\n",
            "Features 136\n",
            "Classes 2\n",
            "\n",
            "-----\n",
            "IMDB-BINARY - GIN0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5639, Test Accuracy: 0.670 ± 0.067, Duration: 12.266\n",
            "The best ans = 0.67000 +- 0.06700\n",
            "-----\n",
            "IMDB-BINARY - GIN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5685, Test Accuracy: 0.672 ± 0.050, Duration: 14.453\n",
            "The best ans = 0.67200 +- 0.05029\n",
            "-----\n",
            "Name = IMDB-BINARY - Mode; = GIN0(\n",
            "  (conv1): GINConv()\n",
            "  (convs): ModuleList(\n",
            "    (0-3): 4 x GINConv()\n",
            "  )\n",
            "  (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
            "): Desc = 0.67000 +- 0.06700\n",
            "Name = IMDB-BINARY - Mode; = GIN(\n",
            "  (conv1): GINConv()\n",
            "  (convs): ModuleList(\n",
            "    (0-3): 4 x GINConv()\n",
            "  )\n",
            "  (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
            "): Desc = 0.67200 +- 0.05029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tN7nj6x3HwMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}